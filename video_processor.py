import cv2
import numpy as np
import streamlit as st
import tempfile
import os
from datetime import datetime
from collections import defaultdict

from utils import get_mediapipe_pose
from frame_instance import FrameInstance
from posture_process import posture_process


class VideoProcessor:
    def __init__(self):
        self.pose = get_mediapipe_pose()
        self.posture_stats = defaultdict(int)
        self.total_frames = 0
        self.good_frames = 0
        
    def process_video(self, video_file, output_path=None):
        """
        å¤„ç†ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å¤„ç†åçš„è§†é¢‘è·¯å¾„å’Œç»Ÿè®¡æ•°æ®
        """
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„è§†é¢‘
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(video_file.read())
            input_path = tmp_file.name
        
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = "output_videos"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            output_path = os.path.join(output_dir, f"processed_video_{timestamp}.mp4")
        
        try:
            # æ‰“å¼€è§†é¢‘æ–‡ä»¶
            cap = cv2.VideoCapture(input_path)
            if not cap.isOpened():
                st.error("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
                return None, None
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼ˆä½¿ç”¨æ›´å…¼å®¹çš„ç¼–ç å™¨ï¼‰
            # å°è¯•å¤šç§ç¼–ç å™¨ï¼Œç¡®ä¿æµè§ˆå™¨å…¼å®¹æ€§
            fourcc_options = [
                cv2.VideoWriter_fourcc(*'avc1'),  # H.264ç¼–ç ï¼Œæµè§ˆå™¨å…¼å®¹æ€§å¥½
                cv2.VideoWriter_fourcc(*'xvid'),  # XVIDç¼–ç 
                cv2.VideoWriter_fourcc(*'mp4v'),  # åŸæœ‰ç¼–ç ä½œä¸ºåå¤‡
                cv2.VideoWriter_fourcc(*'X264'),  # å¦ä¸€ç§H.264å®ç°
            ]
            
            out = None
            for fourcc in fourcc_options:
                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
                if out.isOpened():
                    break
            
            if not out or not out.isOpened():
                st.error("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ ¼å¼")
                return None, None
            
            # é‡ç½®ç»Ÿè®¡
            self.posture_stats = defaultdict(int)
            self.total_frames = 0
            self.good_frames = 0
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            frame_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è½¬æ¢ä¸ºRGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # åˆ›å»ºå¸§å®ä¾‹å¹¶å¤„ç†
                frame_instance = FrameInstance(frame_rgb, self.pose)
                
                if frame_instance.validate():
                    # è¿›è¡Œåå§¿æ£€æµ‹å¤„ç†ï¼ˆåŒ…æ‹¬ç»˜åˆ¶éª¨éª¼çº¿å’Œåé¦ˆï¼‰
                    posture_process(frame_instance, frame_instance.get_frame_width(), frame_instance.get_frame_height())
                    
                    # åˆ†æåå§¿å¹¶è®°å½•ç»Ÿè®¡
                    self._analyze_posture(frame_instance, frame_instance.get_frame_width(), frame_instance.get_frame_height())
                    
                    processed_frame = frame_instance.get_frame()
                else:
                    processed_frame = frame_rgb
                
                # è½¬æ¢å›BGRç”¨äºå†™å…¥
                frame_bgr = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)
                out.write(frame_bgr)
                
                # æ›´æ–°è¿›åº¦
                frame_count += 1
                progress = frame_count / total_frames
                progress_bar.progress(progress)
                status_text.text(f'å¤„ç†è¿›åº¦: {frame_count}/{total_frames} å¸§ ({progress:.1%})')
            
            # é‡Šæ”¾èµ„æº
            cap.release()
            out.release()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(input_path)
            
            # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
            progress_bar.empty()
            status_text.empty()
            
            # éªŒè¯å¹¶è½¬æ¢è§†é¢‘æ ¼å¼
            self.validate_and_convert_video(output_path)
            
            return output_path, self._generate_statistics()
            
        except Exception as e:
            st.error(f"è§†é¢‘å¤„ç†å‡ºé”™: {str(e)}")
            if os.path.exists(input_path):
                os.unlink(input_path)
            if os.path.exists(output_path):
                os.unlink(output_path)
            return None, None
    
    def validate_and_convert_video(self, output_path):
        """
        éªŒè¯è§†é¢‘æ–‡ä»¶å¹¶å°è¯•è½¬æ¢ä¸ºWebå…¼å®¹æ ¼å¼
        """
        if not os.path.exists(output_path):
            return False, "è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
        
        try:
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸è¯»å–
            cap = cv2.VideoCapture(output_path)
            if not cap.isOpened():
                return False, "è¾“å‡ºè§†é¢‘æ–‡ä»¶æŸå"
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            cap.release()
            
            if fps <= 0 or width <= 0 or height <= 0 or total_frames <= 0:
                return False, "è§†é¢‘å‚æ•°æ— æ•ˆ"
            
            # åˆ›å»ºWebå…¼å®¹ç‰ˆæœ¬
            web_compatible_path = output_path.replace('.mp4', '_web.mp4')
            
            # ä½¿ç”¨ffmpegè¿›è¡Œæ ¼å¼è½¬æ¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                import subprocess
                cmd = [
                    'ffmpeg', '-i', output_path,
                    '-c:v', 'libx264',    # ä½¿ç”¨libx264ç¼–ç å™¨
                    '-preset', 'fast',       # å¿«é€Ÿç¼–ç 
                    '-crf', '23',          # è´¨é‡è®¾ç½®
                    '-c:a', 'aac',         # éŸ³é¢‘ç¼–ç 
                    '-y',                  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    web_compatible_path
                ]
                subprocess.run(cmd, check=True, capture_output=True)
                
                # æ›¿æ¢åŸæ–‡ä»¶
                os.replace(web_compatible_path, output_path)
                return True, "è§†é¢‘è½¬æ¢å®Œæˆ"
                
            except (ImportError, subprocess.CalledProcessError, FileNotFoundError):
                # å¦‚æœffmpegä¸å¯ç”¨ï¼Œä½¿ç”¨OpenCVé‡æ–°ç¼–ç 
                cap = cv2.VideoCapture(output_path)
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                
                # ä½¿ç”¨H.264ç¼–ç é‡æ–°åˆ›å»ºè§†é¢‘
                fourcc = cv2.VideoWriter_fourcc(*'avc1')
                out = cv2.VideoWriter(web_compatible_path, fourcc, fps, (width, height))
                
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    out.write(frame)
                
                cap.release()
                out.release()
                
                # æ›¿æ¢åŸæ–‡ä»¶
                os.replace(web_compatible_path, output_path)
                return True, "è§†é¢‘é‡æ–°ç¼–ç å®Œæˆ"
                
        except Exception as e:
            return False, f"è§†é¢‘éªŒè¯å¤±è´¥: {str(e)}"
    
    def _analyze_posture(self, frame_instance, frame_width, frame_height):
        """
        åˆ†æåå§¿å¹¶è®°å½•ç»Ÿè®¡æ•°æ®
        """
        self.total_frames += 1
        
        try:
            # è®¡ç®—å…³é”®è§’åº¦ï¼ˆä½¿ç”¨ä¸­å¿ƒç‚¹ï¼‰
            neck_angle = frame_instance.get_angle('nose', 'shldr_center', 'hip_center')
            spine_angle = frame_instance.get_spine_angle()
            
            # åˆ¤æ–­åå§¿è´¨é‡
            neck_good = neck_angle >= 115
            spine_good = spine_angle <= 15
            
            if neck_good and spine_good:
                self.good_frames += 1
                self.posture_stats['è‰¯å¥½'] += 1
            else:
                if not neck_good:
                    if neck_angle < 100:
                        self.posture_stats['ä¸¥é‡ä½å¤´'] += 1
                    else:
                        self.posture_stats['è½»å¾®ä½å¤´'] += 1
                
                if not spine_good:
                    if spine_angle > 25:
                        self.posture_stats['ä¸¥é‡å‰å€¾'] += 1
                    else:
                        self.posture_stats['è½»å¾®å‰å€¾'] += 1
                        
        except Exception as e:
            # è®¡ç®—å¤±è´¥ï¼Œè®°å½•ä¸ºæ— æ³•æ£€æµ‹
            self.posture_stats['æ— æ³•æ£€æµ‹'] += 1
    
    def _generate_statistics(self):
        """
        ç”Ÿæˆåå§¿ç»Ÿè®¡æŠ¥å‘Š
        """
        good_percentage = (self.good_frames / self.total_frames * 100) if self.total_frames > 0 else 0
        
        stats = {
            'æ€»å¸§æ•°': self.total_frames,
            'è‰¯å¥½å¸§æ•°': self.good_frames,
            'è‰¯å¥½æ¯”ä¾‹': f"{good_percentage:.1f}%",
            'è¯¦ç»†ç»Ÿè®¡': dict(self.posture_stats)
        }
        
        return stats


def create_video_analysis_ui():
    """
    åˆ›å»ºè§†é¢‘åˆ†æçš„ç”¨æˆ·ç•Œé¢
    """
    st.header("ğŸ“¹ è§†é¢‘åå§¿åˆ†æ")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ è§†é¢‘æ–‡ä»¶", 
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="æ”¯æŒ MP4, AVI, MOV, MKV æ ¼å¼çš„è§†é¢‘æ–‡ä»¶"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        st.video(uploaded_file)
        
        # å¤„ç†æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘ï¼Œè¯·ç¨å€™..."):
                processor = VideoProcessor()
                output_path, stats = processor.process_video(uploaded_file)
                
                if output_path and stats:                 
                    # æ˜¾ç¤ºåˆ†æè§†é¢‘
                    st.subheader("ğŸ¥ åˆ†æç»“æœè§†é¢‘")
                    st.video(output_path)

                    
                    
                    # ä¸‹è½½é“¾æ¥
                    with open(output_path, "rb") as file:
                        # ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶å
                        filename = os.path.basename(output_path)
                        st.download_button(
                            label="ä¸‹è½½åˆ†æç»“æœè§†é¢‘",
                            data=file.read(),
                            file_name=filename,
                            mime="video/mp4"
                        )
                else:
                    st.error("è§†é¢‘å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ ¼å¼å’Œå†…å®¹ã€‚")
    